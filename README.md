# ğŸ¤– Chatbot with PyTorch + Transformers

A full-stack chatbot project featuring a React frontend and Flask backend. It combines a custom-trained **intent classifier using PyTorch** with **state-of-the-art NLP models** from Hugging Face Transformers â€” specifically **FLAN-T5** for generative question answering and **Pegasus-XSum** for text summarization. The chatbot is able to classify user intent, answer factual questions using Wikipedia summaries, and summarize text input.

---

## ğŸš€ Features

### ğŸ§  1. Intent Classification (PyTorch)
- A feedforward neural network trained in Google Colab using PyTorch.
- Preprocessed user inputs are classified into one of the predefined intent tags.
- Intent labels and training data stored in `intents.json`.
- Artifacts used: `vocab.pkl`, `label_encoder.pkl`, and `lstm_model.pt` (feedforward model).

### ğŸ“š 2. Generative Q&A with FLAN-T5
- Uses **Google FLAN-T5** via Hugging Face Transformers to answer factual questions.
- Fetches relevant context from Wikipedia using `wikipedia` Python module.
- Format: `question: What is AI?` â†’ FLAN-T5 answers based on retrieved Wikipedia summary.

### âœ‚ï¸ 3. Text Summarization with Pegasus
- Triggered with: `summarize: <text>`
- Uses **Google Pegasus-XSum**, a transformer-based summarization model from Hugging Face.
- Produces short, coherent summaries.

### ğŸ›¡ï¸ 4. Fallback
- When the model's confidence is too low, it returns a default fallback response.

---

## ğŸ“ Project Structure

```
chatbot-react-flask/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # Flask backend
â”‚   â”œâ”€â”€ lstm_model.pt          # Trained PyTorch model (feedforward)
â”‚   â”œâ”€â”€ vocab.pkl              # Vocabulary used in training
â”‚   â”œâ”€â”€ label_encoder.pkl      # Scikit-learn label encoder
â”‚   â”œâ”€â”€ intents.json           # Training data for intents
â”‚   â””â”€â”€ .env                   # Environment variables (Hugging Face tokens etc.)
â”‚
â”œâ”€â”€ chatbot/                   # React frontend
â”‚   â”œâ”€â”€ src/                   # React components
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”§ Installation & Setup

### Backend (Flask + PyTorch)
```bash
cd backend
python -m venv venv
venv\Scripts\activate  # On Windows
pip install -r requirements.txt
python app.py
```

### Frontend (React)
```bash
cd chatbot
npm install
npm start
```

---

## ğŸŒ How It Works
- The React frontend sends a POST request to the Flask backend with the user's message.
- Flask:
  - If the message starts with `question:`, it uses FLAN-T5 + Wikipedia.
  - If it starts with `summarize:`, it runs Pegasus-XSum.
  - Otherwise, it classifies the intent using the custom PyTorch model.

---

## ğŸ§ª Example Prompts
```
Hi, how are you?
question: What is Python?
summarize: Artificial Intelligence is a branch of computer science that...
```

---

## ğŸ› ï¸ Tech Stack
- **Frontend**: React, Axios, HTML/CSS
- **Backend**: Flask, PyTorch, Transformers (Hugging Face)
- **Models**:
  - Custom feedforward neural network for intent classification (PyTorch)
  - FLAN-T5 (generative QA)
  - Pegasus-XSum (summarization)

---

## ğŸ” Environment Variables (.env)
Create a `.env` file in the `backend/` folder:
```
HUGGINGFACEHUB_API_TOKEN=your_token_here
```

> âš ï¸ **Make sure your `.env` is in `.gitignore`!**

---

## ğŸ™Œ Acknowledgements
- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [Google Pegasus](https://huggingface.co/google/pegasus-xsum)
- [Google FLAN-T5](https://huggingface.co/google/flan-t5-base)
- PyTorch + Flask

---

## ğŸ“ƒ License
This project is open-source under the [MIT License](LICENSE).
